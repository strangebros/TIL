## 1. 리밸런싱 프로토콜의 진화

### Eager Rebalancing (전통적 방식)

**동작 방식**
```
1. 리밸런싱 트리거 발생
2. 모든 컨슈머가 소유한 파티션을 즉시 반납 (Revoke All)
3. 모든 컨슈머가 소비 중단 → "Stop-the-World"
4. 새로운 할당표 계산 및 배포
5. 모든 컨슈머가 새로운 파티션 할당받고 소비 재개
```

**문제점**
- 컨슈머 그룹 전체가 멈추는 시간 발생 (수 초 ~ 수십 초)
- 파티션 수 × 컨슈머 수가 많을수록 정지 시간 증가
- 네트워크 오버헤드 증가 (모든 파티션을 재할당)

**실제 영향**
- 100개 컨슈머, 1000개 파티션 환경에서 리밸런싱 시 약 10~30초의 처리 중단 발생
- 메시지 지연(Lag) 급증 → 실시간 처리가 필요한 시스템에서 치명적

### Incremental Cooperative Rebalancing (점진적 협력 방식)

**핵심 개선사항**
```
1. 영향받는 파티션만 선별적으로 이동
2. 나머지 파티션은 계속 소비 진행
3. 2단계 프로토콜로 안전성 확보
```

**할당 전략 비교**

| 전략 | 프로토콜 | 특징 |
|------|---------|------|
| `RangeAssignor` | Eager | 토픽별로 순차 할당, 불균형 발생 가능 |
| `RoundRobinAssignor` | Eager | 전체 파티션을 라운드로빈, 균등 분배 |
| `StickyAssignor` | Eager | 기존 할당 최대한 유지 시도 |
| `CooperativeStickyAssignor` | Cooperative | Sticky + 점진적 이동 |

**설정 방법**
```java
props.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, 
    CooperativeStickyAssignor.class.getName());
```

---

## 2. 시나리오별 상세 분석

### ① 신규 컨슈머 합류 (Scale-out)

**전체 시퀀스 다이어그램**
```
Consumer A (기존)     Consumer B (신규)     Coordinator
    |                     |                    |
    |---- Heartbeat ----->|                    |
    |<--- REBALANCE_IN_PROGRESS ------------- |
    |                     |                    |
    |                     |--- JoinGroup ----->|
    |--- JoinGroup ------>|                    |
    |                     |                    |
    |<--- Leader Elected ----------------------|
    |                     |                    |
    |--- SyncGroup ------>|  (Assignment Map)  |
    |                     |                    |
    |<--- Assignment --------------- SyncGroup |
    |                     |<--- Assignment ----|
```

**상세 단계 설명**

1. **FindCoordinator 단계**
```java
// 컨슈머가 그룹 코디네이터를 찾는 과정
// group.id를 해싱하여 __consumer_offsets의 파티션 결정
int partition = Math.abs(groupId.hashCode()) % offsetsTopicPartitions;
// 해당 파티션의 리더 브로커가 코디네이터가 됨
```

2. **JoinGroup 요청 시 전달 정보**
```json
{
  "group_id": "my-consumer-group",
  "member_id": "",  // 첫 요청 시 비어있음
  "protocol_type": "consumer",
  "protocols": [
    {
      "name": "cooperative-sticky",
      "metadata": {
        "subscription": ["topic-1", "topic-2"],
        "user_data": null,
        "owned_partitions": []  // 신규는 비어있음
      }
    }
  ]
}
```

3. **Preparing Rebalance 상태**
- 코디네이터는 `rebalance.timeout.ms` (기본 5분) 동안 대기
- 모든 기존 멤버가 JoinGroup 요청을 보낼 때까지 기다림
- 타임아웃 발생 시 응답한 멤버들끼리만 리밸런싱 진행

4. **Leader Election 로직**
```
- 가장 먼저 JoinGroup 요청을 보낸 컨슈머를 리더로 선정
- 리더는 할당 계산을 수행할 책임이 있음
- 리더 장애 시 다음 멤버가 자동으로 리더가 됨
```

5. **Assignment 계산 (CooperativeStickyAssignor)**
```java
// 리더 컨슈머가 수행하는 할당 로직
Map<String, List<TopicPartition>> currentAssignment = getCurrentOwnership();
Map<String, List<TopicPartition>> newAssignment = calculateOptimalAssignment();

// 변경이 필요한 파티션만 식별
Set<TopicPartition> toRevoke = findPartitionsToRevoke(currentAssignment, newAssignment);
```

### ② Session Timeout 상세

**Heartbeat Thread의 역할**
```java
// 컨슈머 내부의 HeartbeatThread 구조
class HeartbeatThread extends Thread {
    @Override
    public void run() {
        while (!closed) {
            if (coordinatorUnknown()) {
                findCoordinator();
            }
            
            long now = System.currentTimeMillis();
            if (now - lastHeartbeatSend >= heartbeatIntervalMs) {
                sendHeartbeat();
                lastHeartbeatSend = now;
            }
            
            Thread.sleep(heartbeatIntervalMs);
        }
    }
}
```

**타임아웃 감지 메커니즘**
```
Coordinator의 체크 로직:
1. 마지막 하트비트 시간 기록
2. session.timeout.ms 경과 체크
3. 경과 시 Member를 DEAD 상태로 변경
4. 다음 하트비트 응답에 REBALANCE_NEEDED 플래그 전송
```

**실제 로그 예시**
```log
[Consumer clientId=consumer-1] Member consumer-1-xxxxx sending LeaveGroup request 
to coordinator broker-1:9092 (id: 1 rack: null) due to consumer poll timeout 
has expired.

[GroupCoordinator 1]: Preparing to rebalance group my-group in state 
PreparingRebalance with old generation 5 (__consumer_offsets-0) 
(reason: removing member consumer-1-xxxxx on LeaveGroup)
```

### ③ Poll Timeout 시나리오 - 실무 핵심

**발생 메커니즘**
```java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    
    for (ConsumerRecord<String, String> record : records) {
        // 이 처리가 max.poll.interval.ms를 초과하면 문제 발생
        processRecord(record);  // 10초 소요
    }
    
    // poll() 호출이 지연되면서 컨슈머 제외됨
}
```

**문제 시나리오**
```
시간축:
T+0s:   poll() 호출 → 500개 메시지 수신
T+1s:   메시지 처리 시작
T+300s: 처리 완료 (max.poll.interval.ms=300초 설정)
T+301s: poll() 호출 시도
        → 이미 그룹에서 제외됨
        → CommitFailedException 발생
```

**중복 처리 발생 과정**
```
1. Consumer A: offset 100-599 처리 중 (아직 커밋 안됨)
2. max.poll.interval.ms 초과로 Consumer A 제외
3. Rebalancing 발생
4. Consumer B: offset 100부터 다시 할당받음
5. Consumer A: 처리 완료 후 커밋 시도 → 실패
6. Consumer B: offset 100-599 재처리 → 중복 발생
```

**해결 방법**

**방법 1: 배치 크기 조정**
```java
props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 10);  // 기본 500
// 한 번에 처리할 메시지 수를 줄여 처리 시간 단축
```

**방법 2: 처리 시간 모니터링 및 조기 커밋**
```java
long lastPollTime = System.currentTimeMillis();
int processedCount = 0;

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    
    for (ConsumerRecord<String, String> record : records) {
        processRecord(record);
        processedCount++;
        
        long elapsed = System.currentTimeMillis() - lastPollTime;
        
        // max.poll.interval.ms의 80% 도달 시 조기 종료
        if (elapsed > MAX_POLL_INTERVAL_MS * 0.8) {
            consumer.commitSync();
            break;  // 다음 poll()로 이동
        }
    }
    
    lastPollTime = System.currentTimeMillis();
}
```

**방법 3: 비동기 처리 + 수동 오프셋 관리**
```java
ExecutorService executor = Executors.newFixedThreadPool(10);

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    
    if (!records.isEmpty()) {
        // 별도 스레드에서 처리
        executor.submit(() -> {
            for (ConsumerRecord<String, String> record : records) {
                processRecord(record);
            }
        });
        
        // 즉시 poll() 호출 가능
        // 처리 완료 여부는 별도로 추적
    }
}
```

### ④ Incremental Cooperative Rebalancing 상세

**2단계 프로토콜**

**Phase 1: 파티션 이동 계획**
```
1. 리밸런싱 트리거
2. 모든 컨슈머가 현재 소유한 파티션 정보 전송
3. 리더가 이동이 필요한 파티션만 계산
4. "다음 리밸런싱에서 반납할 파티션" 목록 전달
5. 컨슈머들은 계속 소비 진행
```

**Phase 2: 실제 파티션 이동**
```
1. 반납 대상 파티션을 소유한 컨슈머가 해당 파티션만 Revoke
2. 빈 파티션을 새로운 컨슈머에게 할당
3. 나머지 파티션은 영향 없음
```

**실제 할당 변화 예시**
```
초기 상태 (Consumer 3개, Partition 6개):
Consumer A: [P0, P1]
Consumer B: [P2, P3]
Consumer C: [P4, P5]

Consumer D 추가 → Cooperative Rebalancing:

Phase 1 (계획):
Consumer A: [P0, P1] - P1 반납 예정
Consumer B: [P2, P3] - 유지
Consumer C: [P4, P5] - P5 반납 예정
Consumer D: [] - 대기

Phase 2 (실행):
Consumer A: [P0] ← P1만 반납, P0은 계속 소비
Consumer B: [P2, P3] ← 영향 없음
Consumer C: [P4] ← P5만 반납, P4는 계속 소비
Consumer D: [P1, P5] ← 새로 할당받음
```

**Eager vs Cooperative 비교**

| 항목 | Eager | Cooperative |
|------|-------|-------------|
| 중단 파티션 | 전체 | 이동 대상만 |
| 소요 시간 | 길다 (전체 재할당) | 짧다 (부분 이동) |
| Lag 증가 | 크다 | 최소화 |
| 복잡도 | 단순 | 복잡 (2단계) |

---

## 3. Static Membership 완전 가이드

### 핵심 개념

**일반 Dynamic Membership**
```
1. 컨슈머 시작 시 임시 member.id 발급
2. 컨슈머 종료 시 즉시 리밸런싱 발생
3. 재시작 시 새로운 member.id 발급 → 또 리밸런싱
```

**Static Membership**
```
1. 고정된 group.instance.id 사용
2. 컨슈머 종료 시 session.timeout.ms 동안 대기
3. 대기 시간 내 재시작 시 리밸런싱 없이 기존 파티션 재할당
```

### 설정 방법

```java
Properties props = new Properties();
props.put(ConsumerConfig.GROUP_ID_CONFIG, "my-group");

// Static Membership 활성화
props.put(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, "consumer-instance-1");

// session.timeout.ms를 충분히 길게 설정
props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 45000);  // 45초
```

**주의사항**
```
- group.instance.id는 그룹 내에서 고유해야 함
- 동일한 instance.id로 중복 시작 시 기존 인스턴스가 강제 종료됨
- 컨테이너 환경에서는 hostname 또는 pod name 사용 권장
```

### Kubernetes 환경 적용

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka-consumer
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: consumer
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: GROUP_INSTANCE_ID
          value: "$(POD_NAME)"  # kafka-consumer-0, kafka-consumer-1, ...
```

**롤링 업데이트 시 동작**
```
1. Pod-0 종료 시작
2. Session timeout 내에 새로운 Pod-0 시작
3. 동일한 group.instance.id로 재등록
4. 리밸런싱 없이 기존 파티션 그대로 할당
5. Pod-1, Pod-2도 동일하게 순차 처리
```

---

## 4. 실무 최적화 전략

### 파라미터 튜닝 가이드

**시나리오별 권장 값**

**일반 처리 (평균 처리 시간 < 1초)**
```java
session.timeout.ms = 10000        // 10초
heartbeat.interval.ms = 3000       // 3초
max.poll.interval.ms = 300000      // 5분
max.poll.records = 500             // 기본값
```

**무거운 처리 (평균 처리 시간 5-10초)**
```java
session.timeout.ms = 30000         // 30초
heartbeat.interval.ms = 10000      // 10초
max.poll.interval.ms = 600000      // 10분
max.poll.records = 100             // 배치 크기 축소
```

**매우 무거운 처리 (외부 API 호출 등)**
```java
session.timeout.ms = 45000         // 45초
heartbeat.interval.ms = 15000      // 15초
max.poll.interval.ms = 1800000     // 30분
max.poll.records = 10              // 최소 배치
```

### 예외 처리 패턴

**안티패턴: poll() 루프 깨짐**
```java
// 잘못된 예시
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    
    for (ConsumerRecord<String, String> record : records) {
        processRecord(record);  // 예외 발생 시 poll() 루프 중단
    }
}
```

**권장 패턴: 견고한 예외 처리**
```java
while (true) {
    try {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
        
        for (ConsumerRecord<String, String> record : records) {
            try {
                processRecord(record);
            } catch (Exception e) {
                // 개별 메시지 처리 실패 처리
                log.error("Failed to process record: offset={}, partition={}", 
                    record.offset(), record.partition(), e);
                
                // DLQ로 전송 또는 별도 처리
                sendToDeadLetterQueue(record, e);
            }
        }
        
        // 처리 완료 후 커밋
        consumer.commitSync();
        
    } catch (WakeupException e) {
        // 정상 종료 시그널
        break;
    } catch (Exception e) {
        // poll() 자체의 예외 처리
        log.error("Consumer poll failed", e);
    }
}
```

### 모니터링 지표

**필수 메트릭**

```java
// 1. 리밸런싱 빈도
kafka_consumer_group_rebalance_rate_total

// 2. 리밸런싱 지연 시간
kafka_consumer_group_rebalance_latency_ms

// 3. 파티션당 Lag
kafka_consumer_group_lag{partition="0"}

// 4. Heartbeat 실패율
kafka_consumer_group_heartbeat_failure_rate

// 5. Poll 간격
kafka_consumer_poll_interval_ms
```

**알람 설정 예시**
```yaml
# Prometheus Alert Rule
groups:
- name: kafka_consumer
  rules:
  - alert: FrequentRebalancing
    expr: rate(kafka_consumer_group_rebalance_rate_total[5m]) > 0.1
    annotations:
      summary: "리밸런싱이 5분에 0.1회 이상 발생"
      
  - alert: HighLag
    expr: kafka_consumer_group_lag > 10000
    annotations:
      summary: "Lag가 10,000건 초과"
      
  - alert: PollIntervalTooLong
    expr: kafka_consumer_poll_interval_ms > max_poll_interval_ms * 0.9
    annotations:
      summary: "Poll 간격이 max.poll.interval.ms의 90% 초과"
```

---

## 5. 트러블슈팅 체크리스트

### 리밸런싱이 계속 발생하는 경우

**체크 포인트**

1. **로그 확인**
```bash
# 리밸런싱 원인 파악
grep "Preparing to rebalance" consumer.log

# 일반적인 원인:
# - "removing member on LeaveGroup" → Poll timeout
# - "removing member due to session timeout" → Heartbeat 실패
# - "Adding newly discovered coordinator" → 코디네이터 변경
```

2. **파라미터 검증**
```java
// max.poll.interval.ms < 실제 처리 시간 확인
long startTime = System.currentTimeMillis();
processRecords(records);
long elapsed = System.currentTimeMillis() - startTime;

if (elapsed > MAX_POLL_INTERVAL_MS * 0.8) {
    log.warn("Processing time too long: {}ms", elapsed);
}
```

3. **네트워크 상태**
```bash
# 코디네이터와의 연결 확인
netstat -an | grep 9092

# Heartbeat 실패 로그 확인
grep "Failed to send heartbeat" consumer.log
```

### Lag가 계속 증가하는 경우

**분석 단계**

1. **컨슈머 성능 확인**
```java
// 처리 속도 측정
long messageCount = 0;
long startTime = System.currentTimeMillis();

// 1분간 측정
while (System.currentTimeMillis() - startTime < 60000) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    messageCount += records.count();
    processRecords(records);
}

double throughput = messageCount / 60.0;  // 초당 처리량
log.info("Consumer throughput: {} msg/sec", throughput);
```

2. **Producer 속도와 비교**
```
Producer 속도 > Consumer 속도 * 컨슈머 수
→ 컨슈머 증설 필요
```

3. **GC 또는 리소스 부족 확인**
```bash
# JVM GC 로그 확인
-XX:+PrintGCDetails -XX:+PrintGCTimeStamps

# CPU, Memory 사용률 확인
top -p <consumer_pid>
```
